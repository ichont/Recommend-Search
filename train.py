# save_model.py
from sentence_transformers import SentenceTransformer
import numpy as np
import faiss
import os
import pickle
import re


def parse_data(file_path):
    """
    è§£ææ–‡æœ¬æ•°æ®æ–‡ä»¶ï¼Œè¿”å›è®°å½•åˆ—è¡¨
    """
    records = []
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read().strip()

    # æŒ‰è®°å½•åˆ†å‰²
    record_blocks = content.split('#\n')

    for block in record_blocks:
        if not block.strip():
            continue

        record = {}
        lines = block.strip().split('\n')
        for line in lines:
            if ':' in line:
                key, value = line.split(':', 1)
                record[key.strip()] = value.strip()

        if record:  # ç¡®ä¿éç©ºè®°å½•
            records.append(record)

    return records


def init_embedding_model():
    """
    åˆå§‹åŒ–å¥å­åµŒå…¥æ¨¡å‹
    """
    return SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2") # åˆ‡æ¢ä½ çš„æ¨¡å‹


def generate_search_text(record):
    """
    ä»è®°å½•ä¸­ç”Ÿæˆç”¨äºæœç´¢çš„æ–‡æœ¬
    """
    keys = ['éšæ‚£æè¿°', 'æ£€æŸ¥ä¾æ®', 'æ•´æ”¹å»ºè®®', 'æ£€æŸ¥å¯¹è±¡']
    return ' '.join(str(record.get(k, '')) for k in keys)


def create_vector_index(records, model):
    """
    åˆ›å»ºFAISSå‘é‡ç´¢å¼•
    """
    texts = [generate_search_text(r) for r in records]
    embeddings = model.encode(texts, show_progress_bar=True)

    # åˆ›å»ºFAISSç´¢å¼•
    dimension = embeddings.shape[1]
    index = faiss.IndexFlatL2(dimension)
    index.add(np.array(embeddings).astype('float32'))

    return index, texts


def save_resources(model, index, texts, records, save_dir="./safe_resources"): # ä¿®æ”¹1
    """
    ä¿å­˜æ‰€æœ‰èµ„æºåˆ°æœ¬åœ°ç›®å½• [1,2](@ref)
    """
    os.makedirs(save_dir, exist_ok=True)

    # ä¿å­˜æ¨¡å‹ï¼ˆä½¿ç”¨SentenceTransformerè‡ªå¸¦çš„ä¿å­˜æ–¹æ³•ï¼‰
    model.save(os.path.join(save_dir, "sentence_model"))

    # ä¿å­˜FAISSç´¢å¼•
    faiss.write_index(index, os.path.join(save_dir, "safety_index.faiss"))

    # ä¿å­˜æ–‡æœ¬å’Œè®°å½•ï¼ˆä½¿ç”¨pickleï¼‰[4,5](@ref)
    with open(os.path.join(save_dir, "texts_records.pkl"), "wb") as f:
        pickle.dump({"texts": texts, "records": records}, f)

    # ä¿å­˜æ¨¡å‹ä¿¡æ¯
    model_info = {
        "model_name": "paraphrase-multilingual-MiniLM-L12-v2", # ä¿®æ”¹4
        "dimension": index.d,
        "num_records": len(records)
    }

    with open(os.path.join(save_dir, "model_info.pkl"), "wb") as f:
        pickle.dump(model_info, f)

    print(f"âœ… èµ„æºå·²ä¿å­˜åˆ° {save_dir} ç›®å½•")
    print(f"ğŸ“Š ä¿å­˜äº† {len(records)} æ¡å®‰å…¨è®°å½•")
    print(f"ğŸ”¢ å‘é‡ç»´åº¦: {index.d}")


def main():
    """
    ä¸»å‡½æ•°ï¼šåŠ è½½æ•°æ®å¹¶ä¿å­˜æ‰€æœ‰èµ„æº
    """
    FILE_PATH = 'data.txt'  # ä¿®æ”¹ä¸ºå®é™…æ–‡ä»¶è·¯å¾„
    SAVE_DIR = "./safe_resources" # ä¿®æ”¹3ï¼Œæ¢æ¨¡å‹è¦æ”¹4ä¸ªåœ°æ–¹

    try:
        # åˆå§‹åŒ–æ¨¡å‹
        print("ğŸ”„ åˆå§‹åŒ–åµŒå…¥æ¨¡å‹...")
        model = init_embedding_model()

        # è§£ææ•°æ®
        print("ğŸ“– è§£ææ•°æ®æ–‡ä»¶...")
        records = parse_data(FILE_PATH)
        print(f"âœ… æˆåŠŸåŠ è½½ {len(records)} æ¡å®‰å…¨è®°å½•")

        # åˆ›å»ºå‘é‡ç´¢å¼•
        print("ğŸ”§ åˆ›å»ºå‘é‡ç´¢å¼•...")
        index, texts = create_vector_index(records, model)

        # ä¿å­˜æ‰€æœ‰èµ„æº
        print("ğŸ’¾ ä¿å­˜èµ„æºåˆ°æœ¬åœ°...")
        save_resources(model, index, texts, records, SAVE_DIR)

        print("ğŸ‰ æ¨¡å‹ä¿å­˜å®Œæˆï¼ç°åœ¨æ‚¨å¯ä»¥è¿è¡Œ test.py è¿›è¡Œå¿«é€ŸæŸ¥è¯¢")

    except FileNotFoundError:
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶ {FILE_PATH}")
        print("è¯·ç¡®ä¿ data.txt æ–‡ä»¶å­˜åœ¨äºå½“å‰ç›®å½•")
    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯ï¼š{e}")


if __name__ == "__main__":
    main()